---
title: "tf_idf_delta8tweets.Rmd"
author: "Drew Walker"
date: "8/6/2021"
output: html_document
---
---
title: "delta8tweets"
author: "Drew Walker"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
bibliography: references.bib
---

# Tidy Adaptation

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#remotes::install_github("slu-openGIS/postmastr")
library(operators)
library(magrittr)
library(stm)
library(here)
library(postmastr)
library(textmineR)
library(tidyverse)
library(tidytext)
library(knitr) #Create nicely formatted output tables
library(kableExtra) #Create nicely formatted output tables
library(formattable) #For the color_tile function
library(lubridate)
library(academictwitteR)
library(tm)
library(tidygeocoder)
library(ggpubr)
library(topicmodels)
library(scales)
library(gt)
library(webshot)
library(epitweetr)

APIToken <- read_csv("apikeys.csv")
api_key <- as.character(APIToken[1,1])
api_secret_key <- as.character(APIToken[1,2])
bearer_token <- as.character(APIToken[1,3])
```

Read in Data

```{r delta8tweets,}
d8_tweets <- readRDS("hashtag_delta8_tweets_and_user_info_jan_2020.rds")
```

# Making discrete date phases for different phases in frequency 

```{r, trends-over-time}

d8_tweets_by_date <- d8_tweets %>% 
  mutate(day = as.Date(created_at.x),
         month = month(day),
         year = year(day)) %>% 
  dplyr::group_by(day) %>% 
  dplyr::summarize(tweets_per_day = n(),
            likes_per_day = sum(public_metrics.x$like_count, na.rm = TRUE),
            retweets_per_day = sum(public_metrics.x$retweet_count, na.rm = TRUE),
            replies_per_day = sum(public_metrics.x$reply_count, na.rm = TRUE),
            quotes_per_day = sum(public_metrics.x$quote_count, na.rm = TRUE))

#breaking into discrete time buckets
first_date <- as.Date("2020-01-01")
second_date <- as.Date("2020-12-01")
third_date <- as.Date("2021-06-01")
today <- lubridate::today()

d8_tweets_by_date_buckets <- d8_tweets_by_date %>% 
  mutate(time_period = case_when(
   between(day, first_date, second_date) ~ "phase_1",
   between(day, second_date, third_date) ~ "phase_2",
   TRUE ~ "phase_3"))

d8_tweets_with_date_merge <- d8_tweets %>% 
  mutate(day = as.Date(created_at.x),
         month = month(day),
         year = year(day))

d8_tf_tweets <- left_join(d8_tweets_with_date_merge,d8_tweets_by_date_buckets)
```

```{r, preprocessing-tweets}
#Remove @ and RT tweet notation
d8_tf_tweets$text <- gsub("RT.*:", "", d8_tf_tweets$text)
d8_tf_tweets$text <- gsub("@.* ", "", d8_tf_tweets$text)
# sub out digits , punctuation
#Should digits be included in case of delta 8, delta 10? 

d8_tf_time_id <- d8_tf_tweets %>% 
  select(id,time_period,text)

d8_tf_tweets$text <- gsub('[[:punct:]]+', '', d8_tf_tweets$text)
text_cleaning_tokens <- d8_tf_tweets %>% 
  tidytext::unnest_tokens(word, text) %>% 
  left_join(d8_tf_time_id, by = "id") %>%
  mutate(raw_text = text)
#remove words? like 

text_cleaning_tokens$word <- gsub('[[:digit:]]+', '', text_cleaning_tokens$word)
text_cleaning_tokens$word <- gsub('^https|^amp$|^delta$|^delta 8$|^thc$|^cbd$|^hemp$|^cannabis$', '', text_cleaning_tokens$word)
#remove anything where word is only 1 character like a i d, remove stopwords
text_cleaning_tokens <- text_cleaning_tokens %>% filter(!(nchar(word) == 1))%>% 
  anti_join(stop_words)
#Stem/lemmatizer?
# https://blogs.cornell.edu/cornellnlp/2019/02/09/choose-your-words-wisely-for-topic-models/ 
# may not need to, is often done to save resources, or combine multiple words to mean same thing. May try to do as a sensitivity check 

#remove commonly occurring words


#remove spaces
time_period_words <- text_cleaning_tokens %>% 
  count(time_period.x,word, sort = TRUE) %>% 
  filter(word != "")

total_words <- time_period_words %>% 
  group_by(time_period.x) %>% 
  summarize(total = sum(n))

time_period_words <- left_join(time_period_words, total_words)

time_period_tf_idf <- time_period_words %>% 
  bind_tf_idf(word,time_period.x,n)

library(forcats)

time_period_tf_idf %>%
  group_by(time_period.x) %>%
  slice_max(tf_idf, n = 15) %>%
  ungroup() %>%
  ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = time_period.x)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~time_period.x, ncol = 2, scales = "free") +
  labs(x = "tf-idf", y = NULL)
```

